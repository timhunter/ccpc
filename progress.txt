Sat Jul 30 08:44:39 EDT 2011


	the original "larsonian" grammar marked July 21st 2002 does not have any lexical entries with the +dat dative movement licensor feature
	   --> running this through Guillaumin's hmg2mcfg works fine
	
	the "stackable" variant includes a whole 2nd set of dative-marked homophonic variants of every verb.
           --> running this  through hmg2mcfg yields 48 error messages of the form
		    How did you manage to get this? move impossible: (: +dat v;: -wh_rel)
		    How did you manage to get this? move impossible: (: +dat v)
		    How did you manage to get this? move impossible: (: +dat v;: -f;: -wh_rel)
		    How did you manage to get this? move impossible: (: +dat v;: -f)

	Both grammars get basic dative sentences right:

		    accepted as category c: John give -ed the book to Mary
		    accepted as category c: John give -ed Mary the book

		    accepted as category C: John give -ed Mary the book
		    accepted as category C: John give -ed the book to Mary

        but Stabler's larsonian1 cleans up all these duplicated lexical entries, relocating the ambiguity inside the choice between covert and over Preposition.

	I believe the original point behind those +dat marked was comparability between the Chomskyan "adjunction" analysis and the Kaynian "promotion" analyses.



Sat Jul 30 10:17:46 EDT 2011
      tikz_qtree output -- has this ever worked?


ERROR: Syntax error: Operator expected
ERROR: tikz_qtree(S 
ERROR: ** here **
ERROR: ('I know that the man who Stephen explain -ed the accident to be -s kind') 
    t158 ('' '' 'I know that the man who Stephen explain -ed the accident to be -s kind') 
        t0 ('' '' '') 
etc

prolog is: Welcome to SWI-Prolog (Multi-threaded, 64 bits, Version 5.10.4)


I was able to use the toplevel like this:
       -I mcfgread -I kbest  -I +camlp5 camlp5o.cma


is there a way to load main.ml into the toplevel?  I think I am getting thwarted by a name-clash with something in camlp5.

        Objective Caml version 3.12.0

	Camlp5 parsing version 6.02.3

# #use "debug.ml";;
- : unit = ()
# #use "loading.ml";;
The files grammar.cmo
and /usr/local/lib/ocaml/camlp5/camlp5o.cma
disagree over interface Grammar
File "main.ml", line 1, characters 0-1:
Error: The files /usr/local/lib/ocaml/camlp5/camlp5o.cma and grammar.cmi
       make inconsistent assumptions over interface Grammar


test with
      ./mcfg_nt grammars/mcfgs/larsonian1.mcfg -o /tmp/result "I know that the man who Stephen explain -ed the accident to be -s kind"
      prolog -q -s tikz_qtreeSWI.pl < maketree.pl

./mcfg_nt grammars/mcfgs/larsonian1.mcfg -o result.tex "I know that the man who Stephen explain -ed the accident to be -s kind"

TODO: how to rescale this diagram? there must be a tikz option for that.
get yields at nodes?


Sat Jul 30 14:15:05 EDT 2011
	  ./mcfg_nt grammars/mcfgs/larsonian1.mcfg -p "John love"
	  this works

	       ./mcfg_nt grammars/wmcfg/larsonian1.wmcfg -p "John love"
	  but this quietly yields nothing.
	  Q. why?
	  A. because John was never mentioned in the training, nor was love.


./mcfg_nt grammars/wmcfg/larsonian1.wmcfg -p "I know that the girl who" > know-girl-who.chart
 this works because it is a prefix of the training sentences whose rules-uses we kept.

rules like this need to be flagged
      580716 / 580716      E_eps --> " " 
      12286 / 12286      t1_tmp1_eps --> " " 
      2787 / 2787      t49_tmp1_6-6 --> " " 
      2787 / 2787      t49_tmp1_eps --> " " 


./mcfg_nt grammars/wmcfg/mini.wmcfg -p "he remember -ed that the" > remember-that-the.chart


Sat Jul 30 18:39:10 EDT 2011

by far the slowest step seems to be the TopoSort

For an example like "he remembered -ed that the" using rules observed with a 2 - example minicorpus
	1430 he remember - ed that the man who sell - ed the house leave - ed the town
	929 they have - ed forget - en that the letter which Dick write - ed yesterday be - s long
we get a graph projection with 331 vertices, 1334 edges. This takes 85 seconds to TopoSort the SCCs on my machine.


first error

CalculateZ[g, gp, mySortedSCCs]

goes fine through
first 320,
second 318,
third 311,
fourth 329,
fifth 328,
then 307 it breaks

Part::pspec: "Part specification \!\(vertexNumber$73729[\"man\"]\) is neither an integer nor a list of integers."

the sixth symbol, t11_tmp1_5-5, could rewrite two waysd

1430 / 2359      t11_tmp1_5-5 --> "man" 
929 / 2359      t11_tmp1_5-5 --> "letter" 

fIXeD.


MapThread[{#1, #2} &, {CalculateZ[g, gp, mySortedSCCs],    vertices}] // TableForm
yields a lot of symbols with Z values far outside of [0,1]

the first one it happens on in vertex 283 which seems to have a weight of 4
"t54_5-5_eps_eps_5-5"


here's an example of where it goes wrong:
{120.\[VeryThinSpace]-Subscript[x, 247]==0}{120.}
vertex 247 somehow gets set equal to 120

t139_5-5_5-5_5-5

Sat Jul 30 20:29:24 EDT 2011
  having made sure the rule probs add up to 1,
  the Zs get calculated, and they end up all 1.0.
  is this right? would it be different at other prefixes or with a bigger set of observations?


Sat Jul 30 23:14:15 EDT 2011
the one I did was remember5

{0.371399, -- making the chart into a grammar, squishing weights inside the [0,1] interval
0.091193, -- extracting the graph projection
83.3819, -- topological sorting of the SCCs
1.23299, -- calculating Z
0.090501, -- tilting the rule probabilities by Z ratios
0.533485} -- working out the entropy of the  tilted grammar

total: 85.715
Hstart = 55.2941

The very first Hstart should be the one for mini.wmcfg itself.


Sun Jul 31 08:05:10 EDT 2011

ideas
  - ask Jiwon to recode TopoSortSCCs following Ocamlgraph
   is there a faster way? quickly create a derived graph, then topo sort that.
      create SCC graph: each node is an SCC, an  edge exists between nodes i,j if there exists any edge in the underlying graph between any member of scc i and scc j

      MakeGraph takes a set S and a predicate P and returns a directed graph with vertex set S and edges (i,j) if P(i,j)....ie same vertices

      FunctionalGraph[f,n]
takes a nonnegative integer n and a function f from {0,1,\[Ellipsis],n-1} onto itself and produces the directed graph with vertex set {0,1,\[Ellipsis],n-1} and edge set {x,f[x]} for each vertex x.

For directed graphs the components {Subscript[c, 1],Subscript[c, 2],\[Ellipsis]} are given in an order such that there are no edges from Subscript[c, i] to Subscript[c, i+1], Subscript[c, i+2], etc.

Contracting Vertices p231

0.324475,0.081998,67.7338,1.82167,0.0964,0.475114
0.327542,0.083722,69.894,1.18025,0.091351,0.484989
0.334346,0.08512,73.1225,1.18429,0.092686,0.499217
0.319238,0.082609,71.7298,1.19433,0.090284,0.477729
0.365709,0.093382,86.3537,1.24072,0.090807,0.492508
0.63627,0.128455,135.875,1.78242,0.131961,0.764297
0.490668,0.124555,133.737,1.78604,0.129954,0.745162
0.402995,0.103293,102.206,1.49141,0.107692,0.61621
0.407088,0.103302,104.34,1.55304,0.106989,0.617123}
0.424225,0.103878,111.084,1.66121,0.108183,0.633446
0.409672,0.101246,107.235,1.63765,0.105844,0.621314
0.404404,0.099404,104.861,1.61259,0.101381,0.604081
0.399649,0.099099,107.805,1.68468,0.104603,0.622126
0.414646,0.100883,112.203,1.77274,0.106767,0.637593

that's
0.965491
0.975244
0.976117
0.975829
0.978677
0.979731
0.98049
0.978806
0.978639
0.978803
0.978464
0.978362
0.978288
0.978189

error messages

at the beginning I get some

Part::partw: Part 307 of {0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,<<255>>} does not exist. >>

??variable capture??? ---> yes it was, in CalculateZ.


$RecursionLimit::reclim: Recursion depth of 256 exceeded. >>
General::stop: Further output of $RecursionLimit::reclim will be suppressed during this calculation. >>

FindRoot::vloc: The variable {0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,<<61>>}[[160]] cannot be localized so that it can be assigned to numerical values. >>

FindRoot::vloc: The variable {0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,<<61>>}[[136]] cannot be localized so that it can be assigned to numerical values. >>

FindRoot::vloc: The variable {0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,<<61>>}[[134]] cannot be localized so that it can be assigned to numerical values. >>

FindRoot::vloc: The variable {0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,<<61>>}[[122]] cannot be localized so that it can be assigned to numerical values. >>


remember1:  no error through SCCs
with Zs, we have trouble: solutions that are zero
{-Subscript[x, 285]==0}{0.}


why  are the first couple SCCS {{294}, {292}, {285}, {303}, {302}, {281}, {5}, {36}, {203}, {201}}  etc all zero?
these guys are all terminals
{"man", "letter", "EMPTY"}

when I run it manually it seems to get the right answer - 1

Sun Jul 31 11:05:17 EDT 2011

vertex and edge counts seem pretty constant, in a way that would be consistent with recopying the grammar in the chart.

doing remember1.chart
vertices305
edges1258
doing remember2.chart
vertices309
edges1262
doing remember3.chart
vertices314
edges1255
doing remember4.chart
vertices311
edges1220
doing remember5.chart
vertices331
edges1334
doing remember6.chart
vertices376
edges1672
doing remember7.chart
vertices377
edges1627
doing remember8.chart
vertices354
edges1395
doing remember9.chart
vertices359
edges1388
doing remember10.chart
vertices366
edges1398
doing remember11.chart
vertices365
edges1376
doing remember12.chart
vertices363
edges1351
doing remember13.chart
vertices368
edges1344
doing remember14.chart
vertices375
edges1354
doing remember15.chart
vertices111
edges174

the entropy values were: {48.0396, 58.3656, 57.3656, 51.3656, 55.2941, 74.9708, 72.0036, 62.2941, 61.2941, 57.2941, 40.7248, 24.5693, 23.5693, 19.5693, 3.},
runtime values in seconds were: {{69.0428, 73.6054, 73.7881, 71.3637, 86.6392, 137.778, 135.881, 105.848, 106.463, 115.187, 108.584, 105.985, 108.701, 114.882,  1.81261}}


idea: compile the Mathematica

p45 of Combinatorica book: l[[i]] = 5
 Mathematica rewrites the entire list l when doing this so modifiying an element of a list is in fact a linear-time op

learn more about the "Compile"


info on BFS p277

p284 The strong connectivity algorithm in Combinatorica is based on DFS Tarjan 72


infor on topo sort p352



Sun Jul 31 14:33:02 EDT 2011

my simplified version of Jiwon's TopoSCC function seems to be much slower
whereas hers takes 86 seconds, mine takes 743.

switching to "Select" takes it down to 430 seconds.
    Select[list,crit,n] picks out the first n elements for which crit is True
still five times slower.



what is the difference between these slow methods, which build G^{SCC} and the one p554 of Cormen Leisersohn & Riverse, which just has 2 invocations of DFS?



Mon Aug  1 19:03:24 EDT 2011
  linear-time SCC finding function straight out of CLR
runtimes: {2.13023, 2.28339, 2.2147, 2.22826, 2.45766, 3.34753, 3.38401, 2.79377, 2.83771, 2.78653, 2.85515, 2.77343, 2.80516, 2.87905, 0.238401}

procedure
  ./train grammars/mcfgs/larsonian1.mcfg fig13.txt > grammars/wmcfg/larsonian1.wmcfg


$TemporaryDirectory
FileNameJoin[{"dir1", "dir2", "file"}]

was getting

total for Z      due to FindRoot
10.8475,        4.78624
10.788,	      4.8212
10.8907        4.66339
11.8806,        5.27115
18.4019         8.21405
12.6567,        5.52294

after instituting the NT -> rules table, the time spend CalculatingZ is usually less than the time spend in the entropy computation.

I took out the eigenvalues computation, which is a form of error-checking. This didn't seem to save much time.


Tue Aug  2 09:59:33 EDT 2011

my footnote 7 from 2001:
In particular, relative clauses in the lyzed as
NP → NP SBAR  	(rule 1)
SBAR → WHNP S 	(rule 2)
tains a trace *T* coindexed with the WHNP.
The total number of structures in which both rule 1 and rule 2 apply is 5489. The total number where the first child of S is null is 4768. This estimate puts the total number of object relatives at 721 and the frequency of object relatives at 0.13135362 and the frequency of subject relatives at 0.86864638.



The rcexample grammar had PC style CR/LF newline. tr -d '\r' gets rid of them. This command

    awk -f addrecipe.awk rcexample-macnewlines.chart

add string-manipulaton fns appropriate for CFGs to each line


allow ChartToGrammar to re-infer the arity of each rule
   nrcexample = Import["!awk -f remove1st.awk rc.chart", "Table"];


problem: my CalculateZ is getting all ones, whereas Jiwon's got a variety of numbers.
fixed. the trouble was in ChartToGrammar which was eagerly normalizing-away the original weights.


problem: some tilting happens in the RC example CFG, but none seems to be happening in the MCFGs.

it's getting
     {1-Subscript[x, 21]==0}
       node t0_tmp1_0-1 Z=1.
on
1 / 4      t0_tmp1_0-1 --> "john" 

should the sum of probs here be 0.25 ??? 

tilting corrected. 


Tue Aug  2 14:56:48 EDT 2011

./mcfg_nt grammars/wmcfg/larsonian1.wmcfg -p "the fact that the girl" > fact.chart

all the SCCs are singletons except two (checked with Combinatorica's fn, mine gets the same answer)
....1, 1, 1, 332, 1, 1, 1, 1, 5, 1, 1, 1, 1.....

the problem with "fact.chart"  is SCC 603, which contains a thicket of mutually-recursive symbols. FindRoot gives up, returning some negative Z values which screw everything else up.

FindRoot::lstol: The line search decreased the step size to within tolerance specified by AccuracyGoal and PrecisionGoal but was unable to find a sufficient decrease in the merit function. You may need more than MachinePrecision digits of working precision to meet these tolerances.

but the issue does not seem to be numerical tolerance. I get the same error message and garbage result if I SetPrecision all the rules in the intersection grammar to some small value, like 6 digits of precision.

Things I've tried that haven't worked / have led to an infinite loop
        - giving FindRoot a bracketed initial condition, ie {x,0,50} to tell the algorithm that we seek solutions in that interval
	      it is interesting to watch it flail around by setting StepMonitor to a fn that prints out the vector length of the currnt candidate solution.
	      can anything useful be said about the max value of Z?? how would we know what to pick as the upper bound?
	        (Z can certainly be greater than 1, and it is in the RC example)
	      read Nederhof and Satta
	- using NSolve[eqns, vars, Reals] instead of FindRoot
	- increasin WorkingPrecision

If you view the candidate solutions being examined as 332-dimensional vectors, their vector-length is skyrocketing as the algorithm proceeds: 10, 120, 1329.93, 2280.02, 2533.26, halt.


Question of the consistency of the unconditioned "base" grammar
for larsonian1.wmcfg spectral radius is .934282
so that is fine.


setting the bound to be [0,2]
gets FindRoot stuck somewhere where the norm is 30717.8



Tue Aug  2 19:31:24 EDT 2011

ok, I get Z=1 identically for all nonterminals when I compute the Zs for the unconditioned grammar. this seems right, since all the rule are there.

when I do "fact.chart" I get the error, presumably due to the 332-vertex thicket, SCC #603.

when I do 
   grammar =   ChartToGrammar[    Import["!sed -e 's/\" \"/EMPTY/' < rc-naive.chart", "Table"],   "<0,S,6>"];
   graph = GraphProjection[grammar]
   SCCs = getSCCs[graph];
   z = CalculateZ[grammar, graph, SCCs]

I get a very reasonable-looking set of Zs, same as Jiwon.



this "thicket" SCC of length 332 appears in nearly every prefix

Wed Aug  3 00:19:51 EDT 2011

here is an example of how the epsilon at 5-5 and eps seem to be interchangeable
for the left dtr, you can either have 5-5 or eps in the last component

and for the right daughter you can have anything as long as it's not all eps and the last component is 5-5.
{{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_eps,t53_5-5_eps_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_eps,t53_5-5_5-5_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_eps,t53_eps_eps_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_eps,t53_eps_5-5_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_5-5,t53_5-5_eps_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_5-5,t53_5-5_5-5_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_5-5,t53_eps_eps_5-5},
{Binary,1,t77_eps_5-5_5-5,t8_eps_5-5_5-5,t53_eps_5-5_5-5}}


Wed Aug  3 08:36:29 EDT 2011

why is the thicket blowing up?
do we get the same result if we divide up nonterminals who rewrite uniformly as 1s?


Thu Aug  4 14:39:30 EDT 2011

the very simple "sleep.pl" grammar derives just two sentences
    john sleeps
and
   mary sleeps

supplying giving the prefix  "john sleeps" leaves 1 bit of entropy: the choice between situated and nonsituated epsilon at the end 
    E_eps --> EMPTY 
and
    E_2-2 --> EMPTY 

4 / 4      t1_tmp1_1-2 --> "sleeps"
4 / 4      t1_tmp2_1-2_2-2 --> t1_tmp1_1-2 E_2-2 [0,0][1,0]
4 / 4      t1_tmp2_1-2_eps --> t1_tmp1_1-2 E_eps [0,0][1,0]


I can make negative Zs appear by adding recursive postmodification to sleep.pl

      [tuesday]::[date].
      [on]::[=date,p_on].
      [v]<<[p_on].

parsing "john sleeps" as a prefix,
the first variable to go negative, Z=-2.5 is "t6_0-1_1-1_1-1"
then S_0-1 gets Z=-1


this t6_0-1_1-1_1-1 is variable number 2. 

from 

60 / 80     t6 --> t4 [0,3;0,0][0,1][0,2]

20 / 80     t6 --> t5 t6 [1,0][1,1][1,2;0,0;0,1;0,2]


we two unary rewrites and four binary:

Unary	3/4	t6_0-1_1-1_1-1	t4_eps_1-1_1-1_0-1 (Z=1)	
Unary	3/4	t6_0-1_1-1_1-1	t4_1-1_1-1_1-1_0-1	 (Z=1)
Binary	1/4	t6_0-1_1-1_1-1	t5_1-1_1-1_1-1 (Z=8)	t6_0-1_1-1_eps (Z=1.5)
Binary	1/4	t6_0-1_1-1_1-1	t5_eps_1-1_1-1 (Z=8)	t6_0-1_1-1_eps (Z=1.5)
Binary	1/4	t6_0-1_1-1_1-1	t5_1-1_1-1_1-1 (Z=8)	t6_0-1_1-1_1-1 (recursive!)
Binary	1/4	t6_0-1_1-1_1-1	t5_eps_1-1_1-1 (Z=8)	t6_0-1_1-1_1-1

this yields an equation with a coef on x > 1, which implies a negative soln.
ie with equal prob we are going back around again accumulating Z=8, blows up.


Q. can we make Z go up arbitrarily high by using more  empties?
  not sure how I can increase the empties themselves.


adding recursive modification pushes the Z of t9_eps_0-1_1-1 



Fri Aug  5 07:30:34 EDT 2011

wrote to jy249 saying: 
My guess is that we are double-counting probability mass due to rules that use e.g. (2,2)
epsilons and "eps" epsilons.  I think this is leading to negative Zs.

Fri Aug  5 08:23:26 EDT 2011

sentence 1..4 ok

division by zero error at sentence 6
   couldn't find a z for t137_0-15_15-15_eps number 4

     t137 --> t136 [0,3;0,0][0,1][0,2] (* move' *)

in fact, there are three:


9  = t136_eps_15-15_eps_0-15
4 = t137_0-15_15-15_eps
and
20 =  t80_15-15_15-15_15-15_0-15

these all get set to zero in CalculateZ as solutions to systems like this:

{3.26527*10^-15-Subscript[x, 9]==0}

should be 3.26... 10^{-15}

A. increased WorkingPrecision



also in sentence 6, this prefix:
      the fact that the cat which
gives this error:
FindRoot::lstol: The line search decreased the step size to within tolerance specified by AccuracyGoal and PrecisionGoal but was unable to find a sufficient decrease in the merit function. You may need more than 17.954589770191003` digits of working precision to meet these tolerances.
---> 20 isn't enough, either. find out 


error:   First::first: "{} has a length of zero and no first element."

trying: ./mcfg_nt grammars/wmcfg/larsonian1.wmcfg -p "he remember -ed that the girl who s mother send -ed the clothe -s" | sed -e 's/" "/EMPTY/' > prefix14.chart

that was due to clothes being plural rather than singular....fixed



stored outcome of test run in variable named
   results6through24
clearly, the most problematic one is sentence 6

  entOfSentence["grammars/wmcfg/larsonian1.wmcfg",keenanhawkins[[6]]]

which takes 4 minutes, 14 seconds on my computer.


Fri Aug  5 11:18:39 EDT 2011

    setting WorkingPrecision to 16, which is the first whole number up from MachinePrecision
    avoids an lstol error, but does yield FindRoot::bddir: "The search direction {1.716127634954749*10^-20,1.716127634954749*10^-20} is not a descent direction for the merit function. The step will be taken without the line search"



Fri Aug  5 16:42:35 EDT 2011

 new design runs getCharts first, creating a large number of files named "prefix<SentenceNumber>-<PrefixNumber>.chart"
 then a function kh takes a number, that's the Keenan-Hawkins sentence number, and maps entOfGrammar across all prefixes of it.

  in serial takes 95 seconds for the first K-H sentence
  in parallel it takes 56 seconds.

now timing all of them....for some reason it craps out at sentence 6.

adding DistributeDefinitions statement

within 60 secs we are up to prefix 6 again. which then seems to stop. NB, I left it running all night.

just doing the first two prefixes of each sentence goes all the way through fine.

both 
  prefix6-18.chart
and
  prefix7-1.chart
seem to run fine through entOfGrammarFile locally.

and if we just set doKH to do kh[6] and kh[7] it continues smoothly (225 seconds)

asking doKH for 8-24 craps out after the first one. something is preventing it from continuing..?

  - trying again after adding pfix and i to the list of module-local variables
  - it continues on to prefix9 ok but craps out in there.


Sat Aug  6 10:05:23 EDT 2011

I still can't figure out why doKH based on ParallelTable  is crapping out after calculating an unpredictable number prefix-entropies.
Brainstorm possible reasons for crapping-out:
  - Could we be running out of some resource, like file descriptors?

44863  sed          0.0   00:00.00 1    0    14    23    136K   240K   396K   17M    2378M  44445 44862 sleeping 501  215
44862  sh           0.0   00:

are still running. get rid of the sed command in entOfGrammarFile.


  - Could there be a problem with Table such that it refuses to construct a matrix with unlike row-lengths?
       No, this works fine: Table[{x,y},{x,1,5},{y,1,x}]

I have re-written it in the For-loop style, avoiding parallel anything. I'm expecting this to take about 2 hours.
  (seems to be going fine past sentence 6), but stops at 8-2)

[ another alternative, to safely collect intermediate results, would be to output the Hstart number to a file that has a related filename. ]





Questions I might want to answer once this thing is working reliably through the entire Keenan-Hawkins set:
 (1)  which entropy (reduction) values are different between thesis-style naive renormalization and Z-ratio renormalization?
  -> calls for implementing the "add up & chop"  method, comparing

  (2) what is the difference between larsonian1 and larsonian-stackable, and the chomskyan grammar?
  -> the latter both should derive stackable RCs

  (3) output prefix probabilities, ie Z values
  -> use zsOfSentence from extrastuff.nb



Mon Aug  8 15:25:05 EDT 2011
  I re-did the subj-obj example from JPR 03 and it comes out the same as in the paper.

  It *is* true that there is a bump on the embedded V "sent" in the obj example but not in the subj example

  however this is also consistent with there just being a lot of entropy reduction after any NP.


Tue Aug  9 16:50:04 EDT 2011
  (3) is done
re: (1) using grammars/wmcfg/larsonian-stackable.wmcfg
            and the training sentence weights from the 2006 article

and

oldStyle[filename_] := Module[{grammar,graph,SCCs,z,gprime},
		    grammar = LocallyNormalize[ChartToGrammar[Import[filename,"Table"]]];
		    entropyOfGrammar[grammar]
];

I get

{14.8941, 21.8496, 21.7141, 26.4565, 26.4565, 26.4565, 34.8866, 42.781, 41.7933, 33.8948, 32.722, 34.8866, 13.312, 15.0483, 14.2778, 3.13918, 0.}
{34.8866, 39.7685, 39.7685, 48.1986, 56.093, 55.1053, 49.455, 48.2823, 48.5306, 48.1986, 26.624, 28.3603, 27.5898, 16.4512, 13.312, 14.1077, 0.}
{14.8941, 27.6293, 26.4565, 34.8866, 42.781, 41.7933, 33.8948, 32.722, 34.8866, 16.6181, 13.312, 15.0483, 14.2778, 0.}
{14.8941, 27.6293, 26.4565, 26.4565, 34.8866, 27.7791, 41.7933, 33.8948, 32.722, 34.8866, 13.312, 20.5828, 19.41, 21.5746, 0.}

vs.

eastlansing/results/stackable.math:
{18.23,16.13,11.94,10.94,18.23,18.23,18.23,20.41,17.99,24.75,20.08,19.08,20.41,17.99,3.93,2.93,0.00,0.00},
{18.23,20.41,28.60,28.60,30.78,28.36,35.12,31.22,30.22,30.78,30.78,28.36,14.30,13.30,10.37,10.37,13.92,0.00},
{18.23,16.13,19.23,18.23,20.41,17.99,24.75,20.08,19.08,20.41,10.37,10.37,3.93,2.93,0.00},
{18.23,16.13,19.23,18.23,18.23,20.41,17.99,24.75,20.08,19.08,20.41,17.99,9.71,8.71,10.05,0.00},

some peaks are shifted earlier: story <- be
ticket <- be
house <- leave

but many others are similar but different magnitude: 
get,right
man,sell,house,town
tell,story, young
ticket,very, matter


Wed Aug 10 09:53:06 EDT 2011
  could the difference have to do with # of lexical entries for the same category? 

20 mary sleeps
20 joseph sleeps
20 john sleeps
20 matthew sleeps
20 mark sleeps
20 luke sleeps

20 / 120     t0_tmp1 --> "luke" 
20 / 120     t0_tmp1 --> "mark" 
20 / 120     t0_tmp1 --> "matthew" 
20 / 120     t0_tmp1 --> "john" 
20 / 120     t0_tmp1 --> "joseph" 
20 / 120     t0_tmp1 --> "mary" 

parsing "john sleeps"

brings down to zero from 2.58496250072116, the unconditioned H of the grammar.

A. Yes. The entropy does seeem to be sensitive to the number of lexical entries.

20 mary sleeps
20 john sleeps
 ===> H_{G} = 1

20 mary sleeps
20 john sleeps
20 joseph sleeps
 ==> H_{G} = 1.58, precisely Log2[3]



fix: eliminate preterminal rules indexing into (n,n) 

    N.B. reminder to SetPrecision in oldStyle to try and speed up the calculation
    -> now accomplished in in LocallyNormalize

in a typical prefix-chart like prefix7-2.chart, there are 140 rules of the form

41 / 11353      t13_tmp1_2-2 --> "ship" 
4 / 11353      t13_tmp1_2-2 --> "sailor" 
167 / 1597      t27_tmp1_2-2 --> "give" 
929 / 1597      t27_tmp1_2-2 --> "show" 

t<catnumber>_tmp1_<n>-<n> --> "word"

these appear to be exactly the preterminal rules.

we call unlexicalize.csh first, which emits a sed command that looks for preterminals situated at the right edge:

postprocess =   StringJoin["./unlexicalize.csh ", ToString[prefixnumber]];
	PrintTemporary[postprocess];
	Run[postprocess];


then, for each prefix, coalesce duplicate rules into just one using sort(1) and uniq(1)

unlexicalizer =  StringJoin["unlexicalize", ToString[prefixnumber], ".sed"];
 cmd  = StringJoin["./mcfg_nt " , unconditionedgrammarfilename,  " -p \"", fragstring, "\" | ", cleanupEpsilon,
" | sed -E -f ",  unlexicalizer, " | sort -k4 | uniq > ", dest];


the numbers I get now are:

{
{8.07966, 10.7148, 10.3768, 12.9808, 12.9808, 12.9808, 17.194,  21.526, 21.526, 17.1812, 16.1812, 17.194, 7.29785, 6.45487, 6.45487,  0., 0.},
{17.194, 20.2786, 20.2786, 24.4919, 28.8238, 28.8238,  25.9855, 24.9855, 24.4919, 24.4919, 14.5957, 13.7527, 13.7527,  7.29785, 7.29785, 7.0012, 0.}, {8.07966, 13.9808, 12.9808, 17.194,  21.526, 21.526, 17.1812, 16.1812, 17.194, 7.29785, 7.29785, 6.45487,  6.45487, 0.},
{8.07966, 13.9808, 12.9808, 12.9808, 17.194, 14.7973, 21.526, 17.1812, 16.1812, 17.194, 7.29785, 9.88339, 8.88339,  9.89616, 0.}
}

which still don't agree with eastlansing/results/stackable.math
The conclusion regarding question (1) is that, although old style and new style differ re:uncertainty due to word-choice within a preterminal category,
that is not the *only* difference between them.

Wed Aug 10 15:18:30 EDT 2011

do the unconditioned grammar like this:

sed -E -f unlexicalizeUnsituated.sed grammars/wmcfg/larsonian1.wmcfg | sort -k 4 | uniq > grammars/wmcfg/larsonian1-unlexicalized.wmcfg


  here are my simulated "Old Style" entropy-of-prefix values for the first four sentences of keenanhawkins using larsonian-stackable.wmcfg
  These forgo Z-ratio renormalization in favor of just local renormalization. They reflect an "unlexicalization" intended to simulate the thesis code's blindness to specific word choice. 
  ie in the thesis code item.ml:168 the function "itemify" which doesn't keep track of the choice of particular word, only the Minimalist Grammar feature list that categorizes that word.

15.0234	8.07966	10.7148	10.3768	12.9808	12.9808	12.9808	17.194	21.526	21.526	17.1812	16.1812	17.194	7.29785	6.45487	6.45487	0.	0.
15.0234	17.194	20.2786	20.2786	24.4919	28.8238	28.8238	25.9855	24.9855	24.4919	24.4919	14.5957	13.7527	13.7527	7.29785	7.29785	7.0012	0.
15.0234	8.07966	13.9808	12.9808	17.194	21.526	21.526	17.1812	16.1812	17.194	7.29785	7.29785	6.45487	6.45487	0.			
15.0234	8.07966	13.9808	12.9808	12.9808	17.194	14.7973	21.526	17.1812	16.1812	17.194	7.29785	9.88339	8.88339	9.89616	0.		

 here are the results from
     1. downloading http://courses.cit.cornell.edu/jth99/eastlansing.tar.gz
     2. add larsonian-stackable.pl to the tests/ directory
     3. change the training weights in runme.ml to be the ones from the published 06 article, ie the Brown corpus RC counts obtained with Tregex, ie 1430, 929, 167, 41, 34, 4
     4. change all calls in train and test to refer to the -stackable grammar


{17.61,15.67,11.42,10.42,17.61,17.61,17.61,19.53,17.08,22.78,19.64,18.64,19.53,17.08,4.25,3.25,0.00,0.00},
{17.61,19.53,28.02,28.02,29.94,27.49,33.19,30.85,29.85,29.94,29.94,27.49,14.66,13.66,10.41,10.41,13.48,0.00},
{17.61,15.67,18.61,17.61,19.53,17.08,22.78,19.64,18.64,19.53,10.41,10.41,4.25,3.25,0.00},
{17.61,15.67,18.61,17.61,17.61,19.53,17.08,22.78,19.64,18.64,19.53,17.08,9.23,8.23,9.11,0.00},


now trying with larsonian1....


here's the simulated OldStyle:
15.1377	11.2733	11.9288	11.676	16.226	16.226	16.226	21.9887	27.6534	27.6534	22.2608	20.7608	21.9887	10.8154	7.09233	7.09233	0.	0.
15.1377	21.9887	27.0414	27.0414	32.8041	38.4688	38.4688	34.6902	33.1902	32.8041	32.8041	21.6308	17.9077	17.9077	10.8154	10.8154	11.3416	0.
15.1377	11.2733	18.1179	16.4817	21.8982	27.2226	27.2226	22.2608	20.7608	21.9887	10.8154	10.8154	7.09233	7.09233	0.			
15.1377	11.2733	18.1179	16.7541	16.4817	21.8982	19.301	27.2226	22.2608	20.7608	21.9887	10.8154	11.4454	9.94543	11.1733	0.		

here's the eastlansing version:
{17.43,15.51,10.48,10.10,17.43,17.43,17.43,19.42,17.07,22.79,20.12,18.62,19.42,17.07,4.83,3.83,0.00,0.00},
{17.43,19.42,28.18,28.18,30.18,27.82,33.54,31.65,30.15,30.18,30.18,27.82,15.58,14.58,10.75,10.75,13.13,0.00},
{17.43,15.51,18.56,17.06,18.94,16.73,22.11,20.12,18.62,19.42,10.75,10.75,4.83,3.83,0.00},
{17.43,15.51,18.56,17.06,17.06,18.94,16.73,22.11,20.12,18.62,19.42,17.07,9.37,7.87,8.67,0.00},

these are different, and not just in one direction.


Thu Aug 11 12:00:09 EDT 2011

using the eastlansing distribution, this training set


let sleep_train = [
  (20.0,"mary sleeps");
  (20.0,"john sleeps ");
  (10.0,"mary sleeps on tuesday");
  (10.0,"john sleeps on tuesday");
  (2.0,"mary sleeps on tuesday on tuesday");
  (2.0,"john sleeps on tuesday on tuesday")
];;

and this grammar

[mary]::[n,-f].   [john]::[n,-f].
[sleeps]::[=n,+f,v].
[tuesday]::[date]. [on]::[=date,p_on].  [v]<<[p_on].
startCategory(v).


yields these observations 


  [(("v", ["+f v,-f"]), 64.);   this is t6 rewriting as t4
   (("+f v,-f", ["::=n +f v"; "::n -f"]), 64.); t4 rewriting as t1 and t0
   (("v", ["p_on"; "v"]), 28.);  t6 rewriting as t5 and t6 [recursive]
   (("p_on", ["::=date p_on"; "::date"]), 28.)]   t5 rewriting as t3 and t2


simulating unlexicalization we have

/train grammars/mcfgs/sleep.mcfg sleep.train | sed -E -f unlexicalizeUnsituated.sed | sort -k 4 | uniq



368 / 368     E --> " " 
64 / 64     S --> t6 [0,0;0,1;0,2]
64 / 64     t0 --> E t0_tmp2 [0,0][1,0][1,1]
64 / 64     t0_tmp2 --> t0_tmp1 E [0,0][1,0]
64 / 64     t1 --> E t1_tmp2 [0,0][1,0][1,1]
64 / 64     t1_tmp2 --> t1_tmp1 E [0,0][1,0]
28 / 28     t2 --> E t2_tmp2 [0,0][1,0][1,1]
28 / 28     t2_tmp2 --> t2_tmp1 E [0,0][1,0]
28 / 28     t3 --> E t3_tmp2 [0,0][1,0][1,1]
28 / 28     t3_tmp2 --> t3_tmp1 E [0,0][1,0]
64 / 64     t4 --> t1 t0 [0,0][0,1][0,2][1,0;1,1;1,2]            (("+f v,-f", ["::=n +f v"; "::n -f"]), 64.); t4 rewriting as t1 and t0
28 / 28     t5 --> t3 t2 [0,0][0,1][0,2;1,0;1,1;1,2]             (("p_on", ["::=date p_on"; "::date"]), 28.)]   t5 rewriting as t3 and t2
64 / 92     t6 --> t4 [0,3;0,0][0,1][0,2]                             (("v", ["+f v,-f"]), 64.);   this is t6 rewriting as t4
28 / 92     t6 --> t5 t6 [1,0][1,1][1,2;0,0;0,1;0,2]             (("v", ["p_on"; "v"]), 28.);  t6 rewriting as t5 and t6 [recursive]
64 / 64 t0_tmp1  --> terminal0 
64 / 64 t1_tmp1  --> terminal1 
28 / 28 t2_tmp1  --> terminal2 
28 / 28 t3_tmp1  --> terminal3 

this does seem to line up OK,  yields this PCFG:

1.00  	 & +f v,-f & $\rightarrow$ & ::=n +f v & ::n -f & \\ 
1.00  	 & p_on & $\rightarrow$ & ::=date p_on & ::date & \\ 
0.70  	 & v & $\rightarrow$ & +f v,-f & \\ 
0.30  	 & v & $\rightarrow$ & p_on & v & \\ 


yields these entropy values:
{
{1.27,1.27,0.00},
{1.27,1.27,0.00},
{1.27,1.27,1.27,2.00,0.00},
{1.27,1.27,1.27,2.00,0.00},
{1.27,1.27,1.27,2.00,2.00,2.00,0.00},
{1.27,1.27,1.27,2.00,2.00,2.00,0.00},
}


consider "mary *" ie where mary spans 0_1
eastlansing says the entropy of this prefix grammar is 1.27
oldstyle simulation says its 2.0


the eastlansing PCFG is:
1.00  	 & TOP & $\rightarrow$ & (0,1,1,1,1,1):v, & \\ 

28.00  	 & (0,1,1,1,1,1):v, & $\rightarrow$ & (1,1,1,1,1,1):p_on, & (0,1,1,1,1,1):v, & \\                       t6 -> t5 t6
64.00  	 & (0,1,1,1,1,1):v, & $\rightarrow$ & (1,1,1,1,1,1):+f,v,(0,1,-1,-1,-1,-1):-f, & \\                   t6 -> t4
  "a v can either be formed by first adjoing a p_on, or not"

64.00  	 & (1,1,1,1,1,1):+f,v,(0,1,-1,-1,-1,-1):-f, & $\rightarrow$ & (1,1,1,1,1,1)::=n,+f,v, & (0,0,0,1,1,1)::n,-f, & \\    t4 -> t1 t2

28.00  	 & (1,1,1,1,1,1):p_on, & $\rightarrow$ & (1,1,1,1,?_C214,?_C214)::=date,p_on, & (1,1,1,1,1,1)::date, & \\         t5 -> t3 t2


the first rule gets instantiated two different ways:

      28 / 92      t6_0-1_1-1_1-1 --> t5_eps_1-1_1-1     t6_0-1_1-1_1-1 [1,0][1,1][1,2;0,0;0,1;0,2]
      28 / 92      t6_0-1_1-1_1-1 --> t5_eps_1-1_1-1     t6_0-1_1-1_eps [1,0][1,1][1,2;0,0;0,1;0,2]
            the two ways to instantiate (("v", ["p_on"; "v"]), 28.)

      64 / 92      t6_0-1_1-1_eps --> t4_eps_1-1_eps_0-1 [0,3;0,0][0,1][0,2]
            the one way to instantiate (("v", ["+f v,-f"]), 64.)


so, what is the difference between t6_0-1_1-1_1-1 and t6_0-1_1-1_eps ? the one with the situated complement must be made from something that has postmodification, whereas the one that has an unsituated EPS complement must be made from the other kind:

 t6_0-1_1-1_1-1 --> t5_eps_1-1_1-1     t6_0-1_1-1_1-1           ("v", ["p_on"; "v"])
 t6_0-1_1-1_eps --> t4_eps_1-1_eps_0-1                                   ("v", ["+f v,-f"])


this gives you a locally-normalized grammar where the two t6 rewrites don't alternate correctly. There's a distinction between the first adjunction and successive.


Binary	0.5	t6_0-1_1-1_1-1	t5_eps_1-1_1-1	t6_0-1_1-1_eps
              complement  is set to 1-1       "1_on tuesday_1"       unset
Binary	0.5	t6_0-1_1-1_1-1	t5_eps_1-1_1-1	t6_0-1_1-1_1-1
                 remains set                                                    comes in set

Unary	1.	t6_0-1_1-1_eps	t4_eps_1-1_eps_0-1	
                      unset complement    unary


in this version of t6 -> t4, ie       "v" rewriting as "+f v,-f"    we have the unheard v sleeps t1 at 1-1 combining with mary t0 spanning 0-1

Unary	0.5	S_0-1	t6_0-1_1-1_eps	(* using an unsituated axiom *)
Unary	0.5	S_0-1	t6_0-1_1-1_1-1	(* using a situated axiom at (1,1) *)
Binary	0.5	t6_0-1_1-1_1-1	t5_eps_1-1_1-1	t6_0-1_1-1_eps
Binary	0.5	t6_0-1_1-1_1-1	t5_eps_1-1_1-1	t6_0-1_1-1_1-1
Unary	1.	t6_0-1_1-1_eps	t4_eps_1-1_eps_0-1	
Binary	1.	t5_eps_1-1_1-1	t3_eps_1-1_eps	t2_eps_1-1_eps
Binary	1.	t4_eps_1-1_eps_0-1	t1_eps_1-1_eps	t0_eps_0-1_eps
Binary	1.	t3_eps_1-1_eps	E_eps	t3_tmp2_1-1_eps
Binary	1.	t2_eps_1-1_eps	E_eps	t2_tmp2_1-1_eps
Binary	1.	t1_eps_1-1_eps	E_eps	t1_tmp2_1-1_eps
Binary	1.	t0_eps_0-1_eps	E_eps	t0_tmp2_0-1_eps
Preterminal	1.	E_eps	 	
Binary	1.	t3_tmp2_1-1_eps	t3_tmp1_1-1	E_eps
Binary	1.	t2_tmp2_1-1_eps	t2_tmp1_1-1	E_eps
Binary	1.	t1_tmp2_1-1_eps	t1_tmp1_1-1	E_eps
Binary	1.	t0_tmp2_0-1_eps	t0_tmp1_0-1	E_eps
Preterminal	1.	t3_tmp1_1-1	on	
Preterminal	1.	t2_tmp1_1-1	tuesday	
Preterminal	1.	t1_tmp1_1-1	sleeps	
Preterminal	1.	t0_tmp1_0-1	mary	

another thing that is different between eastlansing and mcfgcky2 is the instantiation of

t6 --> t5 t6 [1,0][1,1][1,2;0,0;0,1;0,2]  ie "right-adjoin1"

both use the same operation
28 / 92      t6_0-1_1-1_1-1 --> t5_eps_1-1_1-1 t6_0-1_1-1_eps [1,0][1,1][1,2;0,0;0,1;0,2]   in the third component, t6's complement's right boundary = t5's specifier's left boundary (which is also eps) = t5's head's left boundary which is 1. that means both eps's are 1.
28 / 92      t6_0-1_1-1_1-1 --> t5_eps_1-1_1-1 t6_0-1_1-1_1-1 [1,0][1,1][1,2;0,0;0,1;0,2]


so if t5_eps_1-1_1-1  has his complement field set and t6_0-1_1-1_eps doesn't, the result has it set. but then we know that 


Fri Aug 12 19:23:06 EDT 2011

 with Tim's new fix, oldStyle gets the same values as eastlansing on sleep.pl

we get slightly different values with keenanhawkins. using larsonian1, on which Guillaumin does not raise any warnings,
there is extra entropy reduced at 

1 "boy" before who
2 "girl" before who
3 "girl" before who (and -s)
4        "house" has a higher entropy reduction before "leave"
5 "letter" before which
6 "cat" before which
7 -s
8 "sweet" before which
9 "to" before "be"
10 "boy" before "who"
11 "to" before "be" and -s
12 "to" before "be"
13 "box" before which
14  "girl"  before who
15       "Joe" has a slightly higher entropy reduction before "on"
16 "for" before "be"
17 "girl" before who
18  "girl" before who
19 "boy" before who
20 "boy" before who
21 "girl before who
23 "sailor" before who
24 "woman" before who
25 ?lost count?  "girl" before who


could these disparities reflect the fact that there is actually lexical choice at (n,n) ?

  if s="*" then
        (List.map (function y -> (n,n,y)) (List.filter (function x -> (not (Item.C185.synonymous "" x))) lexicon))

List.length (List.filter (function x -> (not (Item.C185.synonymous "" x))) grammar.Grammar.C185.lexicon);;
- : int = 188

A. No. Unlexicalizing gives much higher prefix-entropy numbers. I don't believe there were obs-ervations of any of those distinctions.


note: these pre-WH entropy reductions of yore seem to be followed by a smaller reduction on the actual WH in the simulated oldstyle.


try the combination: entOfGrammarFile with unlexicalized charts (DONE, looks a lot like the old east lansing))
 now try it with lexicalized  (DONE, we get higher entropies as expected)
they both look pretty much the same.


Fri Aug 12 21:56:18 EDT 2011

Jiwon: why are we getting Greater::nord ????

 using oldStyle now handily replicates the Korean diagrams from the CogSci Paper
       		{0, 0, 0, 6.33737, 0, 20.7952}
		{0, 0, 0, 14.8544, 0, 20.7952}


{11.2579, 19.5952, 23.7639, 17.4266, 20.7952, 0.}
{11.2579, 19.5952, 32.281, 17.4266, 20.7952, 0.}


 the new-style method using Z ratios does derive a subject advantage, but the difference is earlier in the string, at the ka NOM marker.

{4.4331571394002, 6.9231961424441, 6.6259901135430, 7.2963487472413, 2.7244591917776, 0.*10^-14}
{4.4331571394002, 1.3057028523234, 7.3339067713981, 7.2963487472413, 2.7244591917776, 0.*10^-14}

 surprisal is just junk.


Q. why is entropyOfGrammarFile['/tmp/prefix8-2.chart"] = 1.3 
         but oldStyle is 19.59

in the Z-ratio renormalized version we've become virtually certain that "kica ka" is a complement

0.01330176782553416	S_0-2	t106_0-2_2-2_2-2
0.986698232174466	S_0-2	t106_eps_eps_0-2

but in the oldStyle these are even:

{
 {"Unary", 0.5, "S_0-2", "t106_0-2_2-2_2-2"},
 {"Unary", 0.5, "S_0-2", "t106_eps_eps_0-2"}
}

t106 : (: C-Decl)

they come in as even:

1301 / 1301      S_0-2 --> t106_0-2_2-2_2-2 [0,0;0,1;0,2]
1301 / 1301      S_0-2 --> t106_eps_eps_0-2 [0,0;0,1;0,2]


upshot: Korean result is pushed forward, to case marker, under  Z
             derivation of the AH yield a nice graph with surprisal
	     maybe show individual predictions on an English sentence? contrast surprisal and entropy reduction?



how to unlexicalize a regular old grammar
sed -E -f unlexicalizeUnsituated.sed grammars/wmcfg/korean.wmcfg | sort -k 4 | uniq > grammars/wmcfg/korean-unlexicalized.wmcfg


Sat Aug 13 07:43:34 EDT 2011

 Q. where is this "nord" error coming from?  in the Korean "/tmp/prefix3-4.chart"
          /tmp/prefix1-3.chart
	  /tmp/prefix3-6.chart
    	  /tmp/prefix2-6.chart
    	  /tmp/prefix5-3.chart
    	  /tmp/prefix4-6.chart
    	  /tmp/prefix7-2.chart
    	  /tmp/prefix7-6.chart
    	  /tmp/prefix8-6.chart
 A. imaginary eigenvalues in the fertility matrix. changed the test to look at the maximum of the Absolute Value.


the choice of first morpheme seems quite informative since the decison between the frequent "ul"-marked inititial sentences is quite unbalanced.

changing the training set so that "reporter" and "senator" can occur in every NP position eliminates this while keeping the bump on the NOM marker, 2nd morpheme.

upshot: I've noticed that in switching from oldStyle to new, the SRC/ORC contrast in Korean is pushed forward Korean result is pushed forward, to case marker. How is it with the English RCs?
A. very similar shapes to oldstyle, just sparser overall.


3 to 4?
the 8-5 to 8-6 transition loses an alternative

ok: korean. prefix4-4.chart vs prefix8-4.chart

oldStyle obliterates some distinction that exists in charts 4-3 and 8-3 in 4-4 and 8-4
SRC: 23.76 -> 17.42
ORC: 32.281 -> 17.42

newStyle
SRC: 6.25 -> 7.29  (goes up)
ORC:  7.33 -> 7.29 (goes down)


distinctions in 8-3
"t156_3-3_3-3_3-3_0-3_3-3"  t156 : (: +wh C-Rel;: -epp;: -wh) is three ways ambiguous 0.3/0.3/0.3
      Binary	0.333333	t156_3-3_3-3_3-3_0-3_3-3	t23_3-3_3-3_3-3	t127_0-2_eps_2-3_3-3
      Binary	0.333333	t156_3-3_3-3_3-3_0-3_3-3	t23_3-3_3-3_3-3	t127_0-3_3-3_3-3_3-3
      Binary	0.333333	t156_3-3_3-3_3-3_0-3_3-3	t23_3-3_3-3_3-3	t127_eps_eps_0-3_3-3

this is it. So what I really want to know is, what is the entropy of the category "t156_3-3_3-3_3-3_0-3_3-3" before and after?

In[197]:= {entropyOfT156three[LocallyNormalize[eightthree]],entropyOfT156four[LocallyNormalize[eightfour]]}
Out[197]= {19.7177,16.2252}
In[198]:= {entropyOfT156three[LocallyNormalize[fourthree]],entropyOfT156four[LocallyNormalize[fourfour]]}
Out[198]= {18.3939,16.2252}

In[206]:= {entropyOfT156three[GloballyNormalize[fourthree]],entropyOfT156four[GloballyNormalize[fourfour]]}
Out[206]= {6.0538317283507,9.4577991572290}
In[207]:= {entropyOfT156three[GloballyNormalize[eightthree]],entropyOfT156four[GloballyNormalize[eightfour]]}
Out[207]= {4.9390229098699,9.4577991572290}

Sat Aug 13 22:58:42 EDT 2011
  the English SRC/ORC contrast works fine newStyle.

Q. what is the nonterminal that controls the distinction between SRC and ORC in the korean grammar?

SRC example:   uywon ul kongkyekhan kica ka yumyenghaycyessta
ORC example:   kica ka kongkyekhan uywon i yumyenghaycyessta

the T-rel movement rule is either checking +nom on the -wh mover,  or checking the +nom on the other, nonmoving argument
t127 : (: T-Rel -epp;: -wh)

t151 : (: +nom T-Rel -epp;: -wh;: -nom)  ORC and kica ka is in the specifier
t109 : (: +nom T-Rel -epp;: -nom -wh)    SRC and kica is in the complement
the prior after the first word of prefix 8 is 72/27  on t127. but this does not seem to change.


the entropy of

t127_0-1_1-1_1-1_1-1
t127_0-2_ 2-2_ 2-2_ 2-2

does seem to change, downwardly from 5.7 to 3.63

t156 : (: +wh C-Rel;: -epp;: -wh)

t156_2-2_2-2_2-2_0-2_2-2  uses t127

and has a choice between this version: t127_0-2_2-2_2-2_2-2 and this version
t127_eps_eps_0-2_2-2  84/15

after the second word it becomes more likely we've just seen the kica ka in the specifier of t127 .27/.72 ---> .84/.15


these ratios are both halfs under oldstyle
